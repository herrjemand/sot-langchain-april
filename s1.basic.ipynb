{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.embeddings import OllamaEmbeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- OpenAI ----- #\n",
    "chat_model = ChatOpenAI()\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# ----- Ollama ----- #\n",
    "# chat_model = ChatOllama()\n",
    "# embeddings = OllamaEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic basics\n",
    "\n",
    "Just invoking basic invoke(predict)\n",
    "\n",
    "> Note: .invoke() has replaced .predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model.invoke(\"Hello, how are you?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model.invoke(\"What is the reason of life, universe, and everything?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer to this question is subjective and can vary depending on individual beliefs and perspectives. Some may believe that the reason for life, the universe, and everything is to seek happiness, fulfillment, and personal growth. Others may believe that the purpose is to learn, evolve, and contribute to the greater good of humanity. Ultimately, the reason for life, the universe, and everything is a deeply philosophical and existential question that may not have a definitive answer.\n",
      "The answer to the question of the reason of life, universe, and everything is a philosophical and existential one that has been debated for centuries. Some believe that the reason for existence is to seek enlightenment or spiritual fulfillment, others think it is to simply survive and reproduce, while others suggest that there may not be a predetermined reason at all. Ultimately, the answer may vary depending on individual beliefs, values, and perspectives.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "chat_model = ChatOpenAI(temperature=0)\n",
    "\n",
    "print(chat_model.invoke(\"What is the reason of life, universe, and everything?\").content)\n",
    "\n",
    "chat_model = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "print(chat_model.invoke(\"What is the reason of life, universe, and everything?\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic chain\n",
    "\n",
    "Chain is a way to create a sequence of operations. It is a way to create a pipeline of operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain, ConversationChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain = ConversationChain(\n",
    "    llm=chat_model,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# .run() was replaced with .invoke()\n",
    "\n",
    "conversation_chain.invoke(\"How is it going?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain.invoke(\"What was my question again?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatMessagePromptTemplate\n",
    "\n",
    "\n",
    "yoda_chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=PromptTemplate.from_template(\"You are a helpful assistant that speaks in riddles, like Master Yoda. {input}\")\n",
    ")\n",
    "\n",
    "yoda_chain.run(\"What is the meaning of life?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "title_chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=PromptTemplate.from_template(\"Generate article title based on user input. {input}\"),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain = SimpleSequentialChain(\n",
    "    chains=[title_chain, yoda_chain],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain = chain.run(\"Internships in the tech industry\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
